что такое latency?; latency; задержка?||
Latency — суммарное время от отправки запроса до получения первого релевантного ответа (первого токена). Включает препроцессинг, передачу данных, inference и postprocessing.

что такое inference?; inference; инференс?||
Inference — выполнение модели для генерации ответа (выполнение, не обучение). Могут быть CPU/GPU инференс, батчинг, кэширование.

что такое контекстное окно?; context window; окно контекста||
Контекстное окно — максимальный объём токенов, который модель может обработать одним запросом (например, GPT-2 — 1024 токена).

что такое RAG?; Что такое RAG?; retrieval-augmented generation||
RAG — подход, при котором сначала ищут релевантные документы (retrieval), затем подставляют их в промпт и генерируют ответ моделью, что уменьшает галлюцинации.

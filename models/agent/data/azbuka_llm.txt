АЗБУКА LLM — ключевые термины, которые необходимо знать для защиты проекта

Агент (LLM-Agent) — автономная система на основе LLM, способная ставить подзадачи, использовать инструменты (API, код, память), принимать решения и завершать задачи. Агентность усиливает LLM за счёт планирования и действий.
Авторегрессия (Autoregression) — принцип работы LLM, при котором модель предсказывает следующий токен на основе всех предыдущих. Autoregressive модели генерируют текст последовательно, что создаёт ограничение по скорости.

Базовая модель (Base Model) — LLM без дообучения. Обладает общими знаниями, но не адаптирована под инструкции.
Beam Search — детерминированный метод генерации текста, который выбирает сразу несколько лучших продолжений и затем выбирает финальный вариант.

Векторные представления (Embeddings) — численные представления текста, которые используются в поиске, кластеризации и RAG.
Валидация — проверка корректности модели на данных, не участвовавших в обучении.

Галлюцинации (Hallucinations) — случаи, когда LLM придумывает факты, которые не соответствуют действительности. Смягчаются RAG, проверкой фактов и ограничением генерации.

Декодирование (Decoding) — процесс преобразования распределения вероятности по токенам в текст (greedy, top-k, top-p, beam search).
Детерминизм — свойство генерации, при котором один и тот же ввод → один и тот же вывод (например, beam search, temperature=0).

Естественный язык (NLP) — область ИИ, в которой работают LLM: понимание, генерация, перевод текста.

Жадная генерация (Greedy search) — самый простой метод генерации: выбирается токен с максимальной вероятностью. Быстрый, но менее творческий.

Zero-shot — модель решает задачу без примеров в промпте.
Загрузка весов — процесс инициализации модели параметрами из файла (bin/safetensors).

Inference (Инференс) — выполнение модели: процесс генерации ответа.  
Важно: «обучение» — training, «исполнение» — inference.
Инструкция (Instruction) — запрос в стиле «Сделай X»; специальные модели обучены под N-инструкций (instruct-finetuned).

Контекстное окно (Context Window) — максимальное количество токенов, которое модель может обработать одновременно.  
Например: GPT-2 ≈ 1024 токена, GPT-3.5 ≈ 16k, GPT-4 ≈ 128k.
Чем больше окно — тем длиннее промпты и документы, которые мы можем использовать в RAG.

Latency (задержка) — время от отправки запроса до получения первого ответа (первого токена). Влияют: размер модели, железо, batch size, autoregressive природа.
LLM (Large Language Model) — большая языковая модель на основе трансформера.

Моделька (light LLM) — облегчённая модель для локального запуска (GPT-2, distilled модели, Mistral-instruct 7B).
Многозадачность (Multitask) — способность модели выполнять разные задачи в рамках одного корпуса.

Nucleus Sampling (Top-p) — метод генерации, выбирающий токены только из множества, составляющего p-долю вероятности.
Нормализация — обработка данных, приведение к единым стандартам.

Окно внимания (Attention Window) — часть архитектуры, управляющая тем, какие токены влияют на текущий.
Оверсемплинг / андерсемплинг — балансировка данных.

Параметры модели — количество весов нейросети. Пример: GPT-2 — 124M параметров.
Параллельная генерация — нехарактерна для autoregressive моделей (одно из ограничений).
Память агента — ability агента сохранять факты между шагами.

RAG (Retrieval Augmented Generation) — генерация текста на основе поиска по базе знаний. Подаёт в модель факты из документов → уменьшает галлюцинации.
Регуляризация — способы уменьшить переобучение.

Sampling — вероятностная генерация токенов (top-k, top-p).
Self-Attention — механизм внимания, который лежит в основе трансформера.
Softmax — преобразование логитов в вероятности.

Tokenizer — превращает текст в токены и обратно.
Top-K sampling — генерация только из k наиболее вероятных токенов.
Temperature — параметр “творчества”; при 0 генерация детерминированная.

Устойчивость (Robustness) — способность модели сохранять качество при шуме, разных формулировках.
Ускорение инференса — quantization, FlashAttention, модель 4/8 bit.

Факто-чувствительность (Factuality) — точность фактов в ответах.
Форматирование промпта — структура контекста, влияющая на результат.

Хранилище знаний (Knowledge Base) — набор документов, по которым работает retrieval.
Хеширование — способ проверки целостности данных модели.

Цепочка мыслей (Chain of Thought) — промежуточные рассуждения. Улучшает качество, но удлиняет контекст.

Чат-модели — модели, оптимизированные под диалоговый стиль и соблюдение инструкций.

Шумы в данных — ошибки, влияющие на обучение и генерацию.

Энкодер / Декодер — части архитектуры трансформера (T5 — encoder–decoder, GPT — только decoder).
Эмерджентность — появление способностей при росте размеров модели.

Юнит-тесты — тестирование API и моделей, важная часть CI/CD.

Язык модели — набор данных, на которых модель обучена (английский, русский, мультиязычные). От языка корпуса зависит качество LLM.

БАТЧ-САЙЗ (Batch Size)
Количество примеров, обрабатываемых моделью за один шаг обучения.  
Малый batch → шум выше, обучение стабильнее; большой batch → быстрее, но требует больше VRAM.

БЕНЧМАРК (Benchmark)
Стандартный набор тестов, по которым сравнивают модели.  
Примеры: MMLU, TruthfulQA, GSM8K.

БОЛЬШАЯ ЯЗЫКОВАЯ МОДЕЛЬ (LLM)
Нейросеть на базе трансформера, обученная предсказывать токены. Может анализировать, обобщать и генерировать текст.

ВЕКТОРНАЯ БАЗА ДАННЫХ (Vector DB)
Хранилище эмбеддингов + быстрый поиск похожих векторов.  
Используется в RAG (вытаскивать релевантный контекст).

ВНИМАНИЕ (Attention)
Механизм, позволяющий модели выделять важные части входа.  
Формула: attention(Q, K, V) = softmax(QKᵀ / √dₖ) * V.

SELF-ATTENTION (Самовнимание)
Attention, применённый к самому себе: каждый токен может «смотреть» на другие токены в последовательности.

ГАЛЛЮЦИНАЦИИ (Hallucinations)
Ситуация, когда модель уверенно выдаёт неправду.  
Снижаются RAG, проверкой фактов, строгими промптами.

ГЕЙТ (GATE в MoE)
Механизм выбора экспертов, который определяет, чья часть модели обрабатывает токен.

ГИПЕРПАРАМЕТРЫ
Параметры обучения, задаваемые пользователем: learning rate, batch size, epochs, weight decay, optimizer.

ДЕКОДИНГ (Decoding)
Методы превращения распределений по токенам в текст:  
greedy, top-k, top-p, beam search.

ДЕТЕРМИНИРОВАННОСТЬ
Свойство модели выдавать одинаковые ответы при одинаковом вводе (temperature=0).

ДИСТИЛЛЯЦИЯ (Distillation)
Сжатие модели: маленькая модель учится повторять большую.  
Позволяет создавать лёгкие и быстрые LLM.

ДИФФУЗИОННАЯ LLM
Альтернативный подход к генерации, где токены предсказываются не последовательно, а параллельно через стохастические итерации. Снижает задержку.

EMBEDDING (ЭМБЕДДИНГ)
Векторное представление текста, изображения или звука.  
Используется в RAG, поиске, кластеризации.

EXPERTS (Эксперты в MoE)
Части модели, каждая из которых обучена на своей «зоне задач».  
В MoE модель выбирает нескольких экспертов, а не все слои.

LLM-AS-A-JUDGE
Подход, при котором LLM используется для оценки качества других LLM (например, сравнивает ответы).

ЗАДЕРЖКА (Latency)
Время от запроса до первого токена.  
Высокая latency — проблема autoregressive моделей.

ИНФЕРЕНС (Inference)
Запуск модели для генерации ответа (НЕ обучение).

ИДЕМПОТЕНТНОСТЬ
Свойство функции всегда давать один и тот же результат при повторном вызове с теми же параметрами.

КЭШ KV
Кеширование K и V матриц внимания для ускорения генерации последующих токенов (ускоряет LLM в 5–20 раз).

КВАНТИЗАЦИЯ
Снижение точности веса модели 32-bit → 16-bit → 8-bit → 4-bit.  
Позволяет запускать LLM на CPU.

КОНТЕКСТНОЕ ОКНО
Максимальное число токенов, которые модель может обработать за раз.

ЛОГИТЫ (Logits)
«Сырые» выходы модели перед softmax. Массив вероятностей по всем токенам.

МУЛЬТИМОДАЛЬНОСТЬ
Способность модели работать с текстом, изображениями, аудио, видео.

МУЛЬТИАГЕНТНОСТЬ
Взаимодействие нескольких агентов, каждый из которых решает свою подзадачу.

МЕТРИКИ
Показатели качества модели: accuracy, F1, BLEU, perplexity, ROUGE.

MoE (Mixture of Experts)
Архитектура, которая включает множество экспертов. На каждом токене активны только выбранные эксперты → высокая скорость при больших масштабах.

НАБЛЮДАЕМОСТЬ | Observability
Способность отслеживать внутренние состояния LLM (логиты, attention, токены) для дебага и контроля.

RL — ОБУЧЕНИЕ С ПОДКРЕПЛЕНИЕМ
Модель обучается через награду — reward signal.

OPEN-WEIGHT MODEL
Модель с открытыми весами (Llama 3, Mistral 7B). Отличается от open-source.

ОРКЕСТРАТОР
Система, управляющая запуском агентов и обработкой задач, например LangGraph.

ПАКЕТИРОВАНИЕ (Batching)
Объединение нескольких запросов в один батч для ускорения инференса.

ПАРАМЕТРЫ МОДЕЛИ
Количество весов нейросети.  
Пример: GPT-2 — 124M, Llama 3 — 70B.

ПОТЕРЯ (LOSS)
Функция, показывающая, насколько модель ошиблась.  
Пример: CrossEntropyLoss.

ПРОМПТ-ИНЪЕКЦИЯ
Когда пользователь пытается нарушить инструкции модели, добавив вредные команды в текст.

ПРОМПТ
Ввод пользователя. Может содержать инструкции, примеры, структуру.

ПРУНИНГ (Pruning)
Удаление несущeственных весов для уменьшения модели.

RAG (Retrieval-Augmented Generation)
Генерация текста на основе поиска по документам. Уменьшает галлюцинации.

RLHF
Обучение с подкреплением от человека.  
Структура: supervised → reward model → PPO.

РАССУЖДЕНИЕ (Reasoning)
Способность модели выполнять логические операции, выводы, многошаговые задачи.

СЕМПЛИРОВАНИЕ (Sampling)
Вероятностный выбор следующего токена.  
Параметры: temperature, top-k, top-p.

СИНТЕТИЧЕСКИЕ ДАННЫЕ
Данные, созданные LLM или скриптом, а не собранные вручную.

СЕМАНТИЧЕСКОЕ ПРОСТРАНСТВО
Математическое пространство, где похожие объекты находятся ближе друг к другу (эмбеддинги).

МЕРА СХОЖЕСТИ (Similarity Measure)
Способ сравнить векторы: cosine similarity, dot-product, Euclidean distance.

SPARSE-МОДЕЛЬ
Модель, где активна только часть весов (как MoE).  
Даёт скорость без ухудшения качества.

ТЕНЗОР
Многомерный массив чисел.  
Базовая структура данных в PyTorch/TF.

ТОКЕН (Token)
Минимальная единица текста: слово, часть слова, символ.

ТРАНСФОРМЕР
Архитектура модели, основанная на attention.  
Основные части: self-attention, feed-forward, residual connections.

ФАЙНТЮНИНГ (Fine-tuning)
Дообучение модели под задачу.  
Виды: full, LoRA, QLoRA, PEFT.

CHAIN-OF-THOUGHT
Генерация модели с рассуждениями. Улучшает reasoning.

ZERO-SHOT
Модель решает задачу без примеров.

ONE-SHOT
В промпт добавлен один пример.

FEW-SHOT
В промпт добавлено несколько примеров для улучшения качества.

